{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[],"dockerImageVersionId":31192,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import torch\nimport torch.nn as nn\nimport torch.optim as optim\nimport numpy as np\nimport matplotlib.pyplot as plt","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-12-02T23:40:07.133651Z","iopub.execute_input":"2025-12-02T23:40:07.133936Z","iopub.status.idle":"2025-12-02T23:40:07.138611Z","shell.execute_reply.started":"2025-12-02T23:40:07.133915Z","shell.execute_reply":"2025-12-02T23:40:07.137644Z"}},"outputs":[],"execution_count":4},{"cell_type":"code","source":"# ============================================================\n# Physics-Informed Neural Network (PINN) for Burgers' Equation\n# Inverse Problem: simultaneously learn u(x,t) AND the viscosity ν\n# from PDE + IC/BC + data points (x_data, t_data, u_data).\n# ============================================================\n\nimport torch\nimport torch.nn as nn\nimport torch.optim as optim\nimport numpy as np\nimport matplotlib.pyplot as plt\n\n\n# ============================================================\n# 1. Define the neural network model\n# ============================================================\nclass PINN(nn.Module):\n    \"\"\"\n    PINN model for u(x,t) with an additional trainable parameter ν (nu).\n\n    - Input : (x, t) ∈ ℝ^2\n    - Output: u(x,t) ∈ ℝ\n\n    Architecture:\n      (x,t) --[Linear(2→20), Tanh] → [Linear(20→20), Tanh] → ...\n             → [Linear(20→1)] = u(x,t)\n\n    Additionally:\n      self.nu : a learnable scalar parameter representing viscosity ν.\n                This will be optimized by gradient descent along with NN weights.\n    \"\"\"\n    def __init__(self):\n        super(PINN, self).__init__()\n\n        # A simple fully-connected MLP with Tanh activations.\n        # nn.Sequential groups layers and activations in order.\n        self.hidden = nn.Sequential(\n            nn.Linear(2, 20),   # First layer: input dim=2 (x,t) → hidden dim=20\n            nn.Tanh(),          # Nonlinear activation\n            nn.Linear(20, 20),  # Hidden layer 2\n            nn.Tanh(),\n            nn.Linear(20, 20),  # Hidden layer 3\n            nn.Tanh(),\n            nn.Linear(20, 20),  # Hidden layer 4\n            nn.Tanh(),\n            nn.Linear(20, 1)    # Output layer: hidden dim=20 → output dim=1 (u)\n        )\n\n        # Trainable viscosity parameter ν (inverse problem part).\n        # nn.Parameter makes this scalar part of model.parameters()\n        # so it will be updated by the optimizer.\n        # Initialized randomly in (0,1); we enforce positivity later with .abs().\n        self.nu = nn.Parameter(torch.rand(1, dtype=torch.float32))\n\n    def forward(self, x, t):\n        \"\"\"\n        Forward pass: compute u_θ(x,t).\n\n        Inputs:\n          x : tensor of shape (N,1) → spatial coordinates\n          t : tensor of shape (N,1) → temporal coordinates\n\n        Steps:\n          1) Concatenate x and t into shape (N,2): [x_i, t_i]\n          2) Feed through MLP to get u(x,t).\n\n        Output:\n          u : tensor of shape (N,1)\n        \"\"\"\n        # Concatenate along feature dimension (dim=1):\n        # if x,t each are (N,1), then inputs is (N,2).\n        inputs = torch.cat([x, t], dim=1)\n\n        # Pass the (x,t) features through the hidden MLP.\n        u = self.hidden(inputs)\n\n        return u\n\n\n# ============================================================\n# 2. PDE residual: Burgers' equation (with learned ν)\n# ============================================================\ndef pde_residual(x, t, model):\n    \"\"\"\n    Compute the PDE residual of the 1D Burgers' equation at points (x,t).\n\n    PDE form (we want this to be ≈ 0):\n        u_t + u * u_x - ν * u_xx = 0\n\n    Here ν is not known; we learn it as model.nu (trainable).\n    We also enforce ν ≥ 0 by using model.nu.abs().\n\n    Inputs:\n      x     : tensor of shape (N,1) (collocation points in space)\n      t     : tensor of shape (N,1) (collocation points in time)\n      model : PINN instance, returns u(x,t) and has parameter model.nu\n\n    Output:\n      residual : tensor of shape (N,1)\n                 residual[i] = u_t(x_i,t_i) + u(x_i,t_i)*u_x(x_i,t_i)\n                               - ν * u_xx(x_i,t_i)\n                 which should be near 0 at all collocation points.\n    \"\"\"\n\n    # Enable autograd to track operations on x and t\n    # so that u(x,t) can be differentiated w.r.t. x and t.\n    x.requires_grad_(True)  # in-place: same as x.requires_grad = True but safer\n    t.requires_grad_(True)\n\n    # Forward pass: u(x,t)\n    u = model(x, t)  # shape: (N,1)\n\n    # Compute first derivative wrt time: u_t = ∂u/∂t\n    # autograd.grad arguments:\n    #   outputs       = u\n    #   inputs        = t\n    #   grad_outputs  = torch.ones_like(u) → vector-Jacobian product with all ones,\n    #                      effectively \"pick\" ∂u_i/∂t_i for each i\n    #   create_graph  = True → keep graph to allow second derivatives later\n    u_t = torch.autograd.grad(\n        outputs=u,\n        inputs=t,\n        grad_outputs=torch.ones_like(u),\n        create_graph=True\n    )[0]  # shape (N,1)\n\n    # First derivative wrt space: u_x = ∂u/∂x\n    u_x = torch.autograd.grad(\n        outputs=u,\n        inputs=x,\n        grad_outputs=torch.ones_like(u),\n        create_graph=True\n    )[0]  # shape (N,1)\n\n    # Second derivative wrt space: u_xx = ∂²u/∂x²\n    # Differentiate u_x w.r.t. x again.\n    u_xx = torch.autograd.grad(\n        outputs=u_x,\n        inputs=x,\n        grad_outputs=torch.ones_like(u_x),\n        create_graph=True\n    )[0]  # shape (N,1)\n\n    # Enforce positivity of ν by taking absolute value.\n    # (Otherwise optimizer could push ν to negative values, which is unphysical.)\n    nu_pos = model.nu.abs()\n\n    # PDE residual: r = u_t + u * u_x - ν * u_xx\n    residual = u_t + u * u_x - nu_pos * u_xx\n\n    return residual\n\n\n# ============================================================\n# 3. Initial and boundary conditions\n# ============================================================\ndef initial_condition(x):\n    \"\"\"\n    Initial condition at t = 0:\n\n        u(x, 0) = -sin(pi * x)\n\n    Input:\n      x : tensor of shape (N,1)\n    Output:\n      u_ic(x) : tensor of shape (N,1)\n    \"\"\"\n    return -torch.sin(np.pi * x)\n\n\ndef boundary_condition(x, t):\n    \"\"\"\n    Boundary condition for x = -1 and x = 1 (Dirichlet, homogeneous):\n\n        u(-1, t) = 0,   u(1, t) = 0\n\n    Here x is not actually used; we just return zeros shaped like t.\n\n    Inputs:\n      x : tensor of boundary spatial points (ignored)\n      t : tensor of time points along boundary\n\n    Output:\n      tensor of zeros with same shape as t\n    \"\"\"\n    return torch.zeros_like(t)\n\n\n# ============================================================\n# 4. Create training data: PDE collocation + data points\n# ============================================================\n\n# ------------------------------------------------------------\n# 4.1 Collocation points for PDE/IC/BC\n# ------------------------------------------------------------\n# Spatial grid for x ∈ [-1,1] (200 points)\nx = torch.linspace(-1, 1, 200).view(-1, 1)  # (200,1)\n\n# Temporal grid for t ∈ [0,1] (100 points)\nt = torch.linspace(0, 1, 100).view(-1, 1)   # (100,1)\n\n# Build 2D grid of (x,t) points using meshgrid.\n# x.squeeze(), t.squeeze() → shape (200,), (100,)\n# indexing='xy': first output corresponds to x-axis, second to t-axis.\nx_train, t_train = torch.meshgrid(\n    x.squeeze(),\n    t.squeeze(),\n    indexing='xy')\n\n# Flatten grids to get list of collocation points (N,1), where N = 200*100\nx_train = x_train.reshape(-1, 1)  # (20000,1)\nt_train = t_train.reshape(-1, 1)  # (20000,1)\n\n# ------------------------------------------------------------\n# 4.2 Data points (x_data, t_data, u_data) from reference solution\n# ------------------------------------------------------------\n# Here x_ref, t_ref, exact are assumed pre-loaded reference solution data\n# (e.g., from Burgers.npz as in the code below).\n#\n# x_ref, t_ref, exact shapes (typical):\n#   t_ref: (Nt,) time grid\n#   x_ref: (Nx,) space grid\n#   exact: (Nt, Nx) or similar, then transposed as needed.\n#\n# We flatten them into 1D arrays so that each row is a single (x,t,u) triple.\n\n# Load the reference data\ndata = np.load(\"Burgers.npz\")\nt_ref, x_ref, exact = data[\"t\"], data[\"x\"], data[\"usol\"].T\n\n# Reshape x_ref and t_ref to match the shape of exact\nx_ref, t_ref = np.meshgrid(x_ref, t_ref)\n\n\nx_data = torch.tensor(\n    x_ref.flatten(), dtype=torch.float32).view(-1, 1)  # (N_data,1)\n\nt_data = torch.tensor(\n    t_ref.flatten(), dtype=torch.float32).view(-1, 1)  # (N_data,1)\n\nu_data = torch.tensor(\n    exact.flatten(), dtype=torch.float32).view(-1, 1)  # (N_data,1)\n\n\n# ============================================================\n# 5. Instantiate the model, optimizer\n# ============================================================\n\n# Create PINN instance.\n# It has:\n#   - neural network weights & biases\n#   - trainable viscosity parameter model.nu\nmodel = PINN()  # defaults to CPU; can use model.to(device) if GPU is available\n\n# Adam optimizer on ALL model parameters (including model.nu)\noptimizer = optim.Adam(model.parameters(), lr=0.001)\n\n\n# ============================================================\n# 6. Training loop\n# ============================================================\n\nnum_epochs = 12000\nfor epoch in range(num_epochs):\n    model.train()  # set model to training mode (affects e.g. dropout/batchnorm; here just formality)\n\n    # --------------------------------------------------------\n    # 6.1 Initial condition loss: enforce u(x,0) ≈ -sin(pi x)\n    # --------------------------------------------------------\n    # Evaluate model at t=0 for all spatial collocation points x_train:\n    #   u_pred_ic(x) = u_θ(x, 0)\n    u_pred_ic = model(x_train, torch.zeros_like(x_train))\n\n    # True IC values at same spatial points:\n    u_true_ic = initial_condition(x_train)\n\n    # Mean squared error between predicted and true IC:\n    loss_ic = torch.mean((u_pred_ic - u_true_ic) ** 2)\n\n    # --------------------------------------------------------\n    # 6.2 Boundary condition loss: u(-1,t) ≈ 0, u(1,t) ≈ 0\n    # --------------------------------------------------------\n    # Build boundary x-coordinates for all time points t_train.\n    # Here we reuse t_train (flattened), so BC is enforced on same (flattened) time grid.\n    x_left = torch.full_like(t_train, -1.0)  # (N_collocation,1) with all -1\n    x_right = torch.full_like(t_train, 1.0)  # (N_collocation,1) with all 1\n\n    # Model predictions at x=-1, x=1:\n    u_pred_left = model(x_left, t_train)\n    u_pred_right = model(x_right, t_train)\n\n    # True BC values (here 0) at these points:\n    u_bc_left = boundary_condition(x_left, t_train)    # zeros\n    u_bc_right = boundary_condition(x_right, t_train)  # zeros\n\n    # MSE on both boundaries:\n    loss_bc = torch.mean((u_pred_left - u_bc_left) ** 2) + \\\n              torch.mean((u_pred_right - u_bc_right) ** 2)\n\n    # --------------------------------------------------------\n    # 6.3 PDE residual loss: enforce u_t + u u_x - ν u_xx ≈ 0\n    # --------------------------------------------------------\n    residual = pde_residual(x_train, t_train, model)\n    loss_pde = torch.mean(residual ** 2)\n\n    # --------------------------------------------------------\n    # 6.4 Data loss: fit the reference solution at known data points\n    # --------------------------------------------------------\n    # Evaluate model at measurement/data locations:\n    u_pred_data = model(x_data, t_data)\n\n    # Compare with reference solution u_data:\n    loss_data = torch.mean((u_pred_data - u_data) ** 2)\n\n    # --------------------------------------------------------\n    # 6.5 Total loss: combine physics, IC/BC, and data\n    # --------------------------------------------------------\n    # Data loss is weighted by 100 here to strongly enforce fit to the reference solution.\n    # Weighting is a hyperparameter: DL engineer can tune 100 → 10, 1000, etc.\n    loss = loss_ic + loss_bc + loss_pde + 100.0 * loss_data\n\n    # --------------------------------------------------------\n    # 6.6 Backpropagation and optimizer step\n    # --------------------------------------------------------\n    optimizer.zero_grad()  # clear old gradients\n    loss.backward()        # compute gradients d(loss)/d(parameters)\n    optimizer.step()       # update parameters (NN weights + ν)\n\n    # Logging every 500 epochs: show total loss and current ν estimate\n    if (epoch + 1) % 500 == 0:\n        print(\n            f'Epoch [{epoch + 1}/{num_epochs}], '\n            f'Loss: {loss.item():.6f}, '\n            f'Nu (raw): {model.nu.item():.6f}, '\n            f'Nu (abs): {model.nu.abs().item():.6f}'\n        )\n\n\n# ============================================================\n# 7. Evaluation: predict u(x,t) on a grid for visualization\n# ============================================================\n\n# Build test grid for plotting: 100 points in x and t\nx_test = torch.linspace(-1, 1, 100).view(-1, 1)\nt_test = torch.linspace(0, 1, 100).view(-1, 1)\n\n# 2D meshgrid of test coordinates\nx_test, t_test = torch.meshgrid(\n    x_test.squeeze(),\n    t_test.squeeze(),\n    indexing='xy'\n)\n# Flatten for model input\nx_test = x_test.reshape(-1, 1)  # (10000,1)\nt_test = t_test.reshape(-1, 1)  # (10000,1)\n\nmodel.eval()  # evaluation mode\nwith torch.no_grad():\n    # Predict u(x,t) at test points\n    # If using GPU, better to call .cpu().numpy()\n    u_pred = model(x_test, t_test).cpu().numpy()  # shape (10000,1)\n\n# Reshape back to 2D arrays for contour plotting: (100,100)\nx_test = x_test.numpy().reshape(100, 100)\nt_test = t_test.numpy().reshape(100, 100)\nu_pred = u_pred.reshape(100, 100)\n\n# ============================================================\n# 7. Plotting PINN and reference solutions\n# ============================================================\n# Create subplots for side-by-side comparison\nfig, (ax1, ax2) = plt.subplots(1, 2, figsize=(16, 6))\n\n# Plot the PINN solution as a contour plot\ncontour1 = ax1.contourf(x_test, t_test, u_pred, levels=250, cmap='jet')\nfig.colorbar(contour1, ax=ax1)\nax1.set_xlabel('x')\nax1.set_ylabel('t')\nax1.set_title('Solution of Burgers\\' Equation using PINNs (CPU)')\n\n# Plot the reference solution as a contour plot\ncontour2 = ax2.contourf(x_ref, t_ref, exact, levels=250, cmap='jet')\nfig.colorbar(contour2, ax=ax2)\nax2.set_xlabel('x')\nax2.set_ylabel('t')\nax2.set_title('Reference Solution of Burgers\\' Equation')\n\n# Set the same limits for both plots\nax1.set_xlim([x_ref.min(), x_ref.max()])\nax1.set_ylim([t_ref.min(), t_ref.max()])\nax2.set_xlim([x_ref.min(), x_ref.max()])\nax2.set_ylim([t_ref.min(), t_ref.max()])\n\nplt.tight_layout()\nplt.show()\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-02T23:40:11.741651Z","iopub.execute_input":"2025-12-02T23:40:11.741944Z","iopub.status.idle":"2025-12-02T23:40:11.778191Z","shell.execute_reply.started":"2025-12-02T23:40:11.741923Z","shell.execute_reply":"2025-12-02T23:40:11.776888Z"}},"outputs":[{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m/tmp/ipykernel_47/356109368.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    226\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    227\u001b[0m \u001b[0;31m# Load the reference data\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 228\u001b[0;31m \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Burgers.npz\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    229\u001b[0m \u001b[0mt_ref\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx_ref\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexact\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"t\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"x\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"usol\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mT\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    230\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/numpy/lib/npyio.py\u001b[0m in \u001b[0;36mload\u001b[0;34m(file, mmap_mode, allow_pickle, fix_imports, encoding, max_header_size)\u001b[0m\n\u001b[1;32m    425\u001b[0m             \u001b[0mown_fid\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    426\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 427\u001b[0;31m             \u001b[0mfid\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstack\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menter_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mos_fspath\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"rb\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    428\u001b[0m             \u001b[0mown_fid\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    429\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'Burgers.npz'"],"ename":"FileNotFoundError","evalue":"[Errno 2] No such file or directory: 'Burgers.npz'","output_type":"error"}],"execution_count":7},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# -------------------------------------------------------------\n# Compare learned viscosity ν with the reference value (ground truth)\n# -------------------------------------------------------------\n\n# Reference value of ν from the PDE (e.g., ν = 0.01 / π in Burgers' equation)\nnu_ref = 0.01 / np.pi\n\n# Learned ν from the trained PINN model.\n# model.nu is a torch.nn.Parameter, so we extract its scalar value with .item().\nnu_learned = model.nu.item()  # Actual learned value after training\n\n# Compute the percentage error between learned and reference ν:\n#   percentage_error = |ν_learned - ν_ref| / |ν_ref| × 100 (%)\npercentage_error = abs((nu_learned - nu_ref) / nu_ref) * 100\n\n# Define \"percentage accuracy\" as 100% - percentage_error.\n# (This is a simple way to say \"how close\" ν_learned is to ν_ref.)\npercentage_accuracy = 100 - percentage_error\n\n# Format the results as nicely readable strings (e.g., \"12.34%\")\nformatted_error = f\"Percentage Error: {percentage_error:.2f}%\"\nformatted_accuracy = f\"Percentage Accuracy: {percentage_accuracy:.2f}%\"\n\n# When this cell is run in a notebook, it will display the two formatted strings.\nformatted_error, formatted_accuracy\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-02T23:28:21.854526Z","iopub.execute_input":"2025-12-02T23:28:21.854986Z","iopub.status.idle":"2025-12-02T23:28:21.934135Z","shell.execute_reply.started":"2025-12-02T23:28:21.854956Z","shell.execute_reply":"2025-12-02T23:28:21.932442Z"}},"outputs":[{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)","\u001b[0;32m/tmp/ipykernel_47/4222138701.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Reference value of ν\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mnu_ref\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0.01\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpi\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;31m# learned ν from a random initialization\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mnu_learned\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnu\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# Actual learned value after training\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mNameError\u001b[0m: name 'np' is not defined"],"ename":"NameError","evalue":"name 'np' is not defined","output_type":"error"}],"execution_count":1},{"cell_type":"code","source":"# -------------------------------------------------------------\n# Compare PINN solution with reference solution at selected times\n# -------------------------------------------------------------\n\n# Choose time instances at which we want to slice and compare solutions.\n# These are specific t-values in [0, 1].\ntime_slices = [0.2, 0.4, 0.6, 0.8]  # You can add more time instances if desired\n\n# Number of subplots needed (one per chosen time slice)\nnum_plots = len(time_slices)\n\n# We fix the number of columns for the subplot grid.\ncols = 2  # We use two columns; rows will be computed based on this.\n\n# Compute how many rows we need:\n# - num_plots // cols gives full rows\n# - num_plots % cols adds one more row if there is a leftover plot\nrows = (num_plots // cols) + (num_plots % cols)  # Add one extra row if num_plots is odd\n\n# Create the subplot grid (rows × cols).\n# figsize scales the height with the number of rows to keep aspect reasonable.\nfig, axs = plt.subplots(rows, cols, figsize=(12, 5 * rows))\n\n# If axs is a 2D array of axes, flatten it into a 1D array so we can index with axs[i].\naxs = axs.flatten()\n\n# -------------------------------------------------------------\n# Loop over each chosen time slice and plot reference vs PINN\n# -------------------------------------------------------------\nfor i, t_val in enumerate(time_slices):\n    # ---------------------------------------------------------\n    # 1) Reference solution slice at t ≈ t_val\n    # ---------------------------------------------------------\n\n    # t_ref is assumed to be a 2D array where t_ref[:,0] contains the time grid values.\n    # We find the index of the time in t_ref that is closest to t_val.\n    idx_ref = np.argmin(np.abs(t_ref[:, 0] - t_val))\n\n    # Extract the reference solution at that time index.\n    # exact is assumed to be shaped like (Nt, Nx), so exact[idx_ref, :]\n    # gives the spatial profile u(x, t_val) along x at the chosen time.\n    u_ref_slice = exact[idx_ref, :]\n\n    # ---------------------------------------------------------\n    # 2) PINN solution slice at t = t_val\n    # ---------------------------------------------------------\n\n    # Build a collection of input points (x, t_val) for PINN evaluation.\n    # t_slice is a column vector filled with the chosen time t_val.\n    t_slice = t_val * np.ones((100, 1))  # shape: (100,1)\n\n    # x_slice is a column vector of spatial coordinates in [-1,1].\n    x_slice = np.linspace(-1, 1, 100).reshape(-1, 1)  # shape: (100,1)\n\n    # Switch model to evaluation mode (no dropout, etc.; here mainly for convention).\n    model.eval()\n    with torch.no_grad():\n        # Convert x_slice and t_slice to float32 tensors and feed into the model.\n        # The model outputs u(x,t) for all these points, which we convert to NumPy.\n        u_pinn_slice = model(\n            torch.tensor(x_slice, dtype=torch.float32),\n            torch.tensor(t_slice, dtype=torch.float32)\n        ).numpy()\n\n    # ---------------------------------------------------------\n    # 3) Plot reference vs PINN at this time slice on subplot i\n    # ---------------------------------------------------------\n\n    # Plot reference solution: x_ref[0, :] is the spatial grid,\n    # u_ref_slice is the reference u(x, t_val) at those points.\n    axs[i].plot(x_ref[0, :], u_ref_slice, 'r-', label='Reference Solution')\n\n    # Plot PINN solution: x_slice vs u_pinn_slice\n    axs[i].plot(x_slice, u_pinn_slice, 'b--', label='PINN Solution')\n\n    # Label axes and title for this subplot\n    axs[i].set_xlabel('x')\n    axs[i].set_ylabel('u')\n    axs[i].set_title(f'Solution at t = {t_val}')\n\n    # Add legend to distinguish reference vs PINN curves\n    axs[i].legend()\n\n# -------------------------------------------------------------\n# If the grid has more subplots than we actually used (e.g., odd\n# number of time_slices with 2 columns), delete the unused axes.\n# -------------------------------------------------------------\nfor j in range(num_plots, len(axs)):\n    fig.delaxes(axs[j])  # Remove empty subplot from the figure\n\n# Adjust layout so that labels, titles, and legends do not overlap.\nplt.tight_layout()\n\n# Display the figure with all subplots.\nplt.show()\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-02T23:28:21.934995Z","iopub.status.idle":"2025-12-02T23:28:21.936267Z","shell.execute_reply.started":"2025-12-02T23:28:21.936040Z","shell.execute_reply":"2025-12-02T23:28:21.936061Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}