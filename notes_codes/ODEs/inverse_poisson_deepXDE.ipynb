{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Jt7-XfcUki2D"
      },
      "outputs": [],
      "source": [
        "!pip install deepxde"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import deepxde as dde\n",
        "dde.backend.set_default_backend(\"pytorch\")\n",
        "from deepxde.backend import torch, backend_name\n",
        "import torch\n",
        "\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "'''\n",
        "\"# DeepXDE will internally create tf.keras layers with these specs.\"\n",
        "If there is any issue with torch.sin or other torch.###,\n",
        "just replace it with tf.sin or tf.###.\n",
        "'''\n",
        "\n",
        "# # For reproducibility: fix all random seeds used by DeepXDE / TensorFlow backend\n",
        "# dde.config.set_random_seed(1234)"
      ],
      "metadata": {
        "id": "jEpYxIyiklGt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def reference_u(x):\n",
        "    \"\"\"\n",
        "    Reference (true) solution u(x) used to generate synthetic data.\n",
        "\n",
        "    Here we choose:\n",
        "        u(x) = sin(pi * x)\n",
        "\n",
        "    This is the function that the PINN will try to recover from noisy / sampled data,\n",
        "    and it also implicitly defines the source term q(x) through the Poisson equation.\n",
        "    \"\"\"\n",
        "    return np.sin(np.pi * x)\n",
        "\n",
        "\n",
        "def reference_q(x):\n",
        "    \"\"\"\n",
        "    Reference source term q(x) corresponding to the chosen u(x).\n",
        "\n",
        "    Assume the 1D Poisson equation:\n",
        "        -u''(x) + q(x) = 0\n",
        "\n",
        "    With u(x) = sin(pi * x):\n",
        "        u''(x) = -pi^2 * sin(pi * x)\n",
        "\n",
        "    So plugging into -u''(x) + q(x) = 0 → q(x) = -u''(x) = pi^2 * sin(pi * x).\n",
        "\n",
        "    NOTE: Here we define:\n",
        "        reference_q(x) = -pi^2 * sin(pi * x)\n",
        "    which matches the sign convention used later in the PDE definition\n",
        "    (-u_xx + q = 0) → q = u_xx.\n",
        "    \"\"\"\n",
        "    return -np.pi**2 * np.sin(np.pi * x)\n",
        "\n",
        "\n",
        "# Define the 1D spatial domain: x ∈ [-1, 1]\n",
        "domain = dde.geometry.Interval(-1, 1)\n",
        "\n",
        "\n",
        "def generate_observation_data(n_points=100):\n",
        "    \"\"\"\n",
        "    Generate synthetic observation data (x_obs, u_obs) from the reference solution.\n",
        "\n",
        "    Args:\n",
        "        n_points : number of sample points in the domain.\n",
        "\n",
        "    Returns:\n",
        "        x_values : shape (n_points, 1), evenly spaced points in [-1, 1].\n",
        "        u_values : shape (n_points, 1), reference_u evaluated at x_values.\n",
        "    \"\"\"\n",
        "    # Data generation\n",
        "    x_values = np.linspace(-1, 1, n_points).reshape(-1, 1)\n",
        "    u_values = reference_u(x_values)\n",
        "    return x_values, u_values\n",
        "\n",
        "# Synthetic \"measured\" data for the inverse problem\n",
        "x_observed, u_observed = generate_observation_data()\n",
        "\n",
        "\n",
        "def is_on_boundary(x, on_boundary):\n",
        "    \"\"\"\n",
        "    Boundary indicator function for DeepXDE.\n",
        "\n",
        "    Args:\n",
        "        x           : location in the domain (here, 1D coordinate).\n",
        "        on_boundary : True if the point is on the boundary of the domain.\n",
        "\n",
        "    Here we simply return `on_boundary`, meaning we enforce this BC on\n",
        "    ALL boundary points (both x = -1 and x = 1).\n",
        "    \"\"\"\n",
        "    return on_boundary\n",
        "\n",
        "\n",
        "def boundary_u(x):\n",
        "    \"\"\"\n",
        "    Boundary value function for Dirichlet BC.\n",
        "\n",
        "    We impose:\n",
        "        u(x) = reference_u(x)  on the boundary\n",
        "\n",
        "    Since reference_u(x) = sin(pi * x), this enforces the exact solution\n",
        "    at x = -1 and x = 1.\n",
        "    \"\"\"\n",
        "    return reference_u(x)\n",
        "\n",
        "\n",
        "# Dirichlet boundary condition: u(x) = boundary_u(x) on ∂Ω\n",
        "boundary_condition = dde.icbc.DirichletBC(\n",
        "    domain,\n",
        "    boundary_u,      # target value on the boundary\n",
        "    is_on_boundary,  # function that selects boundary points\n",
        "    component=0      # apply this BC to y[:, 0] (the u component)\n",
        ")\n",
        "\n",
        "\n",
        "# PointSetBC ~ Class instance: 'x_observed' and 'u_observed' are saved in 'PointSetBC'\n",
        "# Point-wise observational data as an additional \"BC\" (data constraint)\n",
        "\"\"\"\n",
        "x_observed : shape (N, 1)\n",
        "   - N observation points in the domain\n",
        "   - each row is a spatial coordinate x where u(x) was measured\n",
        "\n",
        " u_observed : shape (N, 1)\n",
        "   - measured values of u at those locations\n",
        "   - u_observed[i] corresponds to u(x_observed[i])\n",
        "\n",
        "class PointSetBC(BoundaryCondition):\n",
        "    def __init__(self, X, Y, component=0, **kwargs):\n",
        "        self.X = np.array(X)  # observation (input)\n",
        "        self.Y = np.array(Y)  # observed value (a specific output from Network)\n",
        "        self.component = component\n",
        "\n",
        "    => 'component=0' means that model should be trained\n",
        "        in a way that y_pred[:,0] be close to u_observed based on MSE loss\n",
        "\"\"\"\n",
        "observed_data = dde.icbc.PointSetBC(\n",
        "    x_observed,  # observation locations in the domain (input points)\n",
        "    u_observed,  # observed u(x) values at those locations (targets)\n",
        "    component=0  # tell DeepXDE this constraint applies to the 0th output (u, not q)\n",
        ")\n",
        "\n",
        "\n",
        "def poisson_inverse_pde(x, y):\n",
        "    \"\"\"\n",
        "    PDE residual for the inverse Poisson problem.\n",
        "\n",
        "    *** Unknowns: u and q\n",
        "        y[:, 0:1] = u(x)  (state / solution)\n",
        "        y[:, 1:2] = q(x)  (unknown source term we want to infer)\n",
        "\n",
        "    We assume the governing equation:\n",
        "        -u''(x) + q(x) = 0\n",
        "\n",
        "    DeepXDE expects a residual F(x, y, ...) such that F = 0 in the domain.\n",
        "\n",
        "    Steps:\n",
        "        - extract u and q from y\n",
        "        - compute u_xx = ∂²u/∂x² via dde.grad.hessian\n",
        "        - return residual R = -u_xx + q\n",
        "    \"\"\"\n",
        "\n",
        "    # u(x) is the first output of the network\n",
        "    u = y[:, 0:1]\n",
        "\n",
        "    # q(x) is the second output of the network\n",
        "    q = y[:, 1:2]\n",
        "\n",
        "    # Second derivative of u w.r.t. x: u_xx\n",
        "    # component=0 → use y[:, 0] (u); i=0, j=0 → derivative w.r.t. x (since x is 1D here)\n",
        "    u_xx = dde.grad.hessian(y, x, component=0, i=0, j=0)\n",
        "\n",
        "    # Residual: -u_xx + q = 0\n",
        "    return -u_xx + q\n",
        "\n",
        "\n",
        "# Define the PDE inverse problem: domain + PDE + BCs + training/data settings\n",
        "pde_problem = dde.data.PDE(\n",
        "    domain,                     # geometry (1D interval)\n",
        "    poisson_inverse_pde,        # PDE residual function\n",
        "    [boundary_condition,        # Dirichlet BC on u\n",
        "     observed_data],            # point-wise observation constraints on u\n",
        "    num_domain=200,             # interior collocation points for PDE\n",
        "    num_boundary=2,             # number of random boundary points\n",
        "    anchors=x_observed,         # force collocation points to include observed points\n",
        "    num_test=1000,              # number of test points for evaluation\n",
        ")\n",
        "\n",
        "\n",
        "# Neural network architecture: Physics-Informed Feedforward NN (PFNN)\n",
        "# This network outputs [u(x), q(x)] simultaneously.\n",
        "neural_net = dde.nn.PFNN(\n",
        "    [1,                # input dimension: x\n",
        "     [20, 20],         # hidden block 1\n",
        "     [20, 20],         # hidden block 2\n",
        "     [20, 20],         # hidden block 3\n",
        "     2],               # output dimension: 2 (u, q)\n",
        "    \"tanh\",            # activation function\n",
        "    \"Glorot uniform\"   # weight initializer\n",
        ")\n",
        "\n",
        "# Build DeepXDE model from the PDE data + neural network\n",
        "model = dde.Model(pde_problem, neural_net)\n",
        "\n",
        "# Compile model with Adam optimizer\n",
        "# loss_weights:\n",
        "#   [1, 100, 1000] correspond to:\n",
        "#     - PDE residual loss (weight 1)\n",
        "#     - boundary condition loss (weight 100)\n",
        "#     - observation data loss (weight 1000)\n",
        "#   → we emphasize fitting the observed data strongest, then BCs, then PDE.\n",
        "model.compile(\"adam\", lr=1e-4, loss_weights=[1, 100, 1000])\n",
        "\n",
        "# Train the model for 20,000 iterations\n",
        "model.train(iterations=20000)\n",
        "\n"
      ],
      "metadata": {
        "id": "UJqgiQN6kk_3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x_test = domain.uniform_points(500)\n",
        "y_pred = model.predict(x_test)\n",
        "\n",
        "u_predicted = y_pred[:, 0:1]\n",
        "q_predicted = y_pred[:, 1:2]\n",
        "\n",
        "u_actual = reference_u(x_test)\n",
        "q_actual = reference_q(x_test)\n",
        "\n",
        "error_u = dde.metrics.l2_relative_error(u_actual, u_predicted)\n",
        "error_q = dde.metrics.l2_relative_error(q_actual, q_predicted)\n",
        "print(f\"L2 Relative Error in u(x): {error_u:.4e}\")\n",
        "print(f\"L2 Relative Error in q(x): {error_q:.4e}\")\n"
      ],
      "metadata": {
        "id": "cUY8Beukkk8_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure(figsize=(10, 4))\n",
        "plt.subplot(1, 2, 1)\n",
        "plt.plot(x_test, u_actual, label=\"u_true\", linewidth=2)\n",
        "plt.plot(x_test, u_predicted, \"--\", label=\"u_predicted (NN)\")\n",
        "plt.title(\"Recovered Displacement u(x)\")\n",
        "plt.legend()\n",
        "plt.subplot(1, 2, 2)\n",
        "plt.plot(x_test, q_actual, label=\"q_true\", linewidth=2)\n",
        "plt.plot(x_test, q_predicted, \"--\", label=\"q_predicted (NN)\")\n",
        "plt.title(\"Recovered Forcing Field q(x)\")\n",
        "plt.legend()\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "\n",
        "plt.figure()\n",
        "plt.plot(x_test, np.abs(u_actual - u_predicted), label=\"|u_true - u_predicted|\")\n",
        "plt.plot(x_test, np.abs(q_actual - q_predicted), label=\"|q_true - q_predicted|\")\n",
        "plt.title(\"Point-wise Absolute Errors\")\n",
        "plt.legend()\n",
        "plt.grid()\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "Rtc77uBEkk6H"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "VxG2TdyWkk3P"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "from matplotlib.patches import Circle\n",
        "\n",
        "\n",
        "def draw_neural_net_with_labels(ax, layer_sizes,\n",
        "                                node_labels=None,\n",
        "                                neuron_radius=0.03,\n",
        "                                connection_color='k',\n",
        "                                connection_width=0.5):\n",
        "  \"\"\"\n",
        "  Draw a feedforward neural network with customizable neuron labels and layer sizes.\n",
        "  Parameters:\n",
        "  ax : Matplotlib Axes object to draw on\n",
        "  layer_sizes : List of integers indicating neurons in each layer\n",
        "  node_labels : 2D list of LaTeX-compatible labels (one list per layer)\n",
        "  neuron_radius : Radius of neuron circles\n",
        "  connection_color : Color of lines connecting layers\n",
        "  connection_width : Line width for connections\n",
        "  \"\"\"\n",
        "\n",
        "  v_spacing = 1. / float(max(layer_sizes))\n",
        "  h_spacing = 1. / float(len(layer_sizes) - 1)\n",
        "\n",
        "  # Draw neurons\n",
        "  for layer_idx, num_neurons in enumerate(layer_sizes):\n",
        "  layer_top = v_spacing * (num_neurons - 1) / 2.0\n",
        "  for neuron_idx in range(num_neurons):\n",
        "  x = layer_idx * h_spacing\n",
        "  y = layer_top - neuron_idx * v_spacing\n",
        "  circle = Circle((x, y), neuron_radius, edgecolor='k', facecolor='w', zorder=4)\n",
        "  ax.add_patch(circle)\n",
        "\n",
        "  # Add labels if provided\n",
        "  if node_labels and layer_idx < len(node_labels) and neuron_idx < len(node_labels[\n",
        "  ax.text(x, y, node_labels[layer_idx][neuron_idx],\n",
        "  ha='center', va='center', fontsize=10, color='black', zorder=5)\n",
        "\n",
        "  # Draw connections between neurons\n",
        "  for layer_idx, (n_input, n_output) in enumerate(zip(layer_sizes[:-1], layer_sizes[1:])):\n",
        "  layer_top_input = v_spacing * (n_input - 1) / 2.0\n",
        "  layer_top_output = v_spacing * (n_output - 1) / 2.0\n",
        "  for i in range(n_input):\n",
        "  for j in range(n_output):\n",
        "  x0 = layer_idx * h_spacing\n",
        "  y0 = layer_top_input - i * v_spacing\n",
        "  x1 = (layer_idx + 1) * h_spacing\n",
        "  y1 = layer_top_output - j * v_spacing\n",
        "  ax.plot([x0, x1], [y0, y1], color=connection_color, lw=connection_width, zorde\n",
        "\n",
        "\n",
        "\n",
        "# Example: 1 input → 2 hidden → 2 output (u, q)\n",
        "layer_sizes = [1, 4, 4, 2]\n",
        "\n",
        "# Optional: labels per neuron\n",
        "node_labels = [\n",
        "[r\"$x$\"], # Input layer\n",
        "[r\"$h_{11}$\", r\"$h_{12}$\", r\"$h_{13}$\", r\"$h_{14}$\"], # Hidden 1\n",
        "[r\"$h_{21}$\", r\"$h_{22}$\", r\"$h_{23}$\", r\"$h_{24}$\"], # Hidden 2\n",
        "[r\"$u(x)$\", r\"$q(x)$\"] # Output layer\n",
        "]\n",
        "\n",
        "fig, ax = plt.subplots(figsize=(10, 5))\n",
        "draw_neural_net_with_labels(ax, layer_sizes, node_labels)\n",
        "ax.axis('off')\n",
        "\n",
        "plt.title(\"Neural Network Architecture for Inverse Poisson PINN\", fontsize=14)\n",
        "plt.show()\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "A6I_PX3hkk0p"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "GrFKjBHBkkx6"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}