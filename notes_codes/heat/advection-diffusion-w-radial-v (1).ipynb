{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"},"kaggle":{"accelerator":"none","dataSources":[],"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import numpy as np\nimport torch\nimport torch.nn as nn\nimport torch.autograd as autograd\nimport matplotlib.pyplot as plt\nimport matplotlib.animation as animation\nfrom IPython.display import HTML\n\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\nx_min, x_max, y_min, y_max, t_min, t_max = -100, 100, -100, 100, 0, 10\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# ---------------------------------------------\n# PINN model definition\n# ---------------------------------------------\nclass PINN(nn.Module):\n    def __init__(self):\n        super().__init__()\n        # Simple fully-connected neural network:\n        #   input : (x, y, t)  →  3-dimensional\n        #   hidden: three layers of 128 neurons with Tanh activation\n        #   output: scalar u(x,y,t) ∈ (0,1) via Sigmoid\n        #\n        # Sigmoid is used here because the solution u represents a\n        # transported \"blob\" with values between 0 and 1 (like a concentration).\n        self.net = nn.Sequential(\n            nn.Linear(3, 128), nn.Tanh(),\n            nn.Linear(128, 128), nn.Tanh(),\n            nn.Linear(128, 128), nn.Tanh(),\n            nn.Linear(128, 1), nn.Sigmoid()\n        )\n\n    def forward(self, x):\n        # Forward pass: simply apply the Sequential network\n        # x shape: (N, 3) where columns are [x, y, t]\n        # returns: (N, 1) predicted scalar field u(x,y,t)\n        return self.net(x)\n\n\n# ---------------------------------------------\n# Velocity field a(x,y), b(x,y)\n# ---------------------------------------------\ndef velocity(x, y):\n    \"\"\"\n    Compute the radial velocity field (a, b) given spatial coordinates (x, y).\n\n    The analytical definition is:\n        a(x,y) = x / sqrt(x^2 + y^2)\n        b(x,y) = y / sqrt(x^2 + y^2)\n\n    which corresponds to a unit vector pointing radially outward.\n\n    At the origin (x,y) = (0,0), r = 0 and the direction is undefined,\n    so we manually set the velocity to (0,0) there to avoid division by zero.\n    \"\"\"\n    # Radial distance r = sqrt(x^2 + y^2)\n    r = torch.sqrt(x**2 + y**2)\n\n    # a = x / r, but only where r > 0. At r == 0, set a = 0.\n    a = torch.where(r > 0, x / r, torch.zeros_like(r))\n\n    # b = y / r, but only where r > 0. At r == 0, set b = 0.\n    b = torch.where(r > 0, y / r, torch.zeros_like(r))\n\n    # a, b shapes: same as x,y (usually (N,1))\n    return a, b\n\n\n# ---------------------------------------------\n# PDE residual loss: advection–diffusion equation\n# ---------------------------------------------\ndef pde_loss(model, xyt):\n    \"\"\"\n    Compute the physics (PDE) loss for the advection–diffusion equation:\n\n        u_t + a(x,y) u_x + b(x,y) u_y = u_xx + u_yy\n\n    This is enforced at randomly sampled collocation points (x, y, t).\n\n    Args:\n        model: the PINN model u(x,y,t)\n        xyt  : tensor of shape (N, 3) with columns [x, y, t]\n\n    Returns:\n        Scalar tensor: mean squared PDE residual over all collocation points.\n    \"\"\"\n    # We need gradients w.r.t. xyt to compute u_x, u_y, u_t, etc.\n    xyt.requires_grad_(True)\n\n    # Forward pass: u(x,y,t)\n    u = model(xyt)  # shape (N,1)\n\n    # First-order derivatives of u w.r.t. (x,y,t)\n    # autograd.grad returns a tensor of shape (N,3):\n    #   grads[:,0] = ∂u/∂x, grads[:,1] = ∂u/∂y, grads[:,2] = ∂u/∂t\n    grads = autograd.grad(\n        outputs=u,\n        inputs=xyt,\n        grad_outputs=torch.ones_like(u),\n        create_graph=True)[0]\n\n    # Split the gradient into components, each of shape (N,1)\n    u_x, u_y, u_t = grads[:, 0:1], grads[:, 1:2], grads[:, 2:3]\n\n    # Second derivatives u_xx and u_yy via another autograd call\n    # First: differentiate u_x w.r.t xyt, then select x-component for u_xx\n    u_xx = autograd.grad(\n        outputs=u_x,\n        inputs=xyt,\n        grad_outputs=torch.ones_like(u_x),\n        create_graph=True)[0][:, 0:1]\n\n    # Similarly: differentiate u_y w.r.t xyt, then select y-component for u_yy\n    u_yy = autograd.grad(\n        outputs=u_y,\n        inputs=xyt,\n        grad_outputs=torch.ones_like(u_y),\n        create_graph=True\n    )[0][:, 1:2]\n\n    # Extract spatial coordinates (x,y) from xyt\n    x, y = xyt[:, 0:1], xyt[:, 1:2]\n\n    # Compute radial velocity components a(x,y), b(x,y)\n    a, b = velocity(x, y)  # shapes (N,1)\n\n    # PDE residual for each point:\n    #   r(x,y,t) = u_t + a u_x + b u_y - u_xx - u_yy\n    # We reshape a,b to (N,1) just to be explicit.\n    residual = u_t + a.view(-1, 1) * u_x + b.view(-1, 1) * u_y - u_xx - u_yy\n\n    # Physics loss = mean squared residual\n    return (residual**2).mean()\n\n\n# ---------------------------------------------\n# Initial condition loss\n# ---------------------------------------------\ndef ic_loss(model, xyt_ic, u_ic):\n    \"\"\"\n    Initial condition loss at t = 0.\n\n    Args:\n        model : PINN model u(x,y,t)\n        xyt_ic: tensor of shape (N_ic, 3) with t=0 for all rows\n        u_ic  : tensor of shape (N_ic, 1) with prescribed IC values,\n                e.g. 1 inside the disk and 0 outside.\n\n    Returns:\n        Mean squared error between predicted and prescribed IC.\n    \"\"\"\n    u_pred = model(xyt_ic)\n    return ((u_pred - u_ic) ** 2).mean()\n\n\n# ---------------------------------------------\n# Neumann boundary condition loss\n# ---------------------------------------------\ndef bc_loss(model, xyt_bc):\n    \"\"\"\n    Neumann boundary condition loss: ∇u · n = 0 on all edges of the domain.\n\n    The outward normal n is:\n      - left  boundary (x = x_min): n = (-1, 0)\n      - right boundary (x = x_max): n = ( 1, 0)\n      - bottom boundary (y = y_min): n = (0, -1)\n      - top    boundary (y = y_max): n = (0,  1)\n\n    For each boundary point, we compute ∇u and its dot product with n,\n    then minimize (∇u · n)^2.\n\n    Args:\n        model : PINN model u(x,y,t)\n        xyt_bc: tensor of shape (N_bc, 3) containing boundary points.\n\n    Returns:\n        Mean squared normal-derivative (Neumann) residual.\n    \"\"\"\n    # Need gradients w.r.t. xyt_bc for computing spatial derivatives\n    xyt_bc.requires_grad_(True)\n\n    # Forward pass on boundary points\n    u = model(xyt_bc)  # (N_bc,1)\n\n    # Gradient of u w.r.t. (x,y,t)\n    grads = autograd.grad(\n        outputs=u,\n        inputs=xyt_bc,\n        grad_outputs=torch.ones_like(u),\n        create_graph=True\n    )[0]  # shape (N_bc, 3)\n\n    # Extract x,y coordinates (1D tensors: shape (N_bc,))\n    x, y = xyt_bc[:, 0], xyt_bc[:, 1]\n\n    # Initialize normal components nx, ny as zeros\n    # These will be filled with ±1 depending on which boundary each point lies on.\n    nx = torch.zeros_like(x)\n    ny = torch.zeros_like(y)\n\n    # Left boundary: x == x_min → normal (-1, 0)\n    nx[x == x_min] = -1\n    # Right boundary: x == x_max → normal (+1, 0)\n    nx[x == x_max] = 1\n\n    # Bottom boundary: y == y_min → normal (0, -1)\n    ny[y == y_min] = -1\n    # Top boundary: y == y_max → normal (0, +1)\n    ny[y == y_max] = 1\n\n    # Normal derivative ∂u/∂n = ∇u · n = u_x * nx + u_y * ny\n    grad_n = grads[:, 0] * nx + grads[:, 1] * ny  # shape (N_bc,)\n\n    # We want ∂u/∂n = 0, so penalize (∂u/∂n)^2\n    return (grad_n.view(-1, 1) ** 2).mean()\n\n\n# ---------------------------------------------\n# Sampling functions for collocation, IC, and BC\n# ---------------------------------------------\ndef sample_domain(N):\n    \"\"\"\n    Sample N random collocation points inside the full space-time domain:\n\n        x ∈ [x_min, x_max],\n        y ∈ [y_min, y_max],\n        t ∈ [t_min, t_max].\n\n    Returns:\n        Tensor of shape (N, 3) with columns [x, y, t].\n    \"\"\"\n    x = np.random.uniform(x_min, x_max, N)\n    y = np.random.uniform(y_min, y_max, N)\n    t = np.random.uniform(t_min, t_max, N)\n\n    # np.c_[x, y, t] concatenates the 1D arrays column-wise to shape (N,3)\n    return torch.tensor(np.c_[x, y, t], dtype=torch.float32).to(device)\n\n\ndef sample_ic(N):\n    \"\"\"\n    Sample N points for the initial condition at t = 0.\n\n    Initial condition:\n        u(x,y,0) = 1   if x^2 + y^2 < (12.5)^2  (inside the circle)\n                  = 0   otherwise (outside the circle)\n\n    Returns:\n        xyt_ic : tensor (N,3) with t=0\n        u_ic  : tensor (N,1) with corresponding IC values (0 or 1)\n    \"\"\"\n    # Random spatial positions in the domain\n    x = np.random.uniform(x_min, x_max, N)\n    y = np.random.uniform(y_min, y_max, N)\n\n    # Time is fixed to 0 for all IC points\n    t = np.zeros(N)\n\n    # Indicator for being inside the initial circle of radius 12.5\n    # u = 1 inside, 0 outside\n    u = ((x**2 + y**2) < (12.5)**2).astype(np.float32)\n\n    xyt_ic = torch.tensor(np.c_[x, y, t], dtype=torch.float32).to(device)\n    u_ic = torch.tensor(u[:, None], dtype=torch.float32).to(device)\n    return xyt_ic, u_ic\n\n\ndef sample_bc(N):\n    \"\"\"\n    Sample boundary points on all four edges of the spatial domain\n    for Neumann boundary conditions.\n\n    For each edge we create N points:\n        - y = y_min, x ∈ [x_min, x_max]\n        - y = y_max, x ∈ [x_min, x_max]\n        - x = x_min, y ∈ [y_min, y_max]\n        - x = x_max, y ∈ [y_min, y_max]\n\n    For each boundary point we also randomly select a time t ∈ [t_min, t_max].\n\n    Returns:\n        Tensor of shape (4N, 3) with all boundary points stacked.\n    \"\"\"\n    pts = []\n\n    # We encode each boundary by a tuple:\n    #   (range_for_free_coord, fixed_value, axis_flag)\n    #\n    # axis_flag = 1  → vary x, fix y (horizontal edges)\n    # axis_flag = 0  → vary y, fix x (vertical edges)\n    for v, const, axis in [\n        ((x_min, x_max), y_min, 1),  # bottom edge: y = y_min\n        ((x_min, x_max), y_max, 1),  # top edge:    y = y_max\n        ((y_min, y_max), x_min, 0),  # left edge:   x = x_min\n        ((y_min, y_max), x_max, 0),  # right edge:  x = x_max\n    ]:\n        # v is a 2-tuple (start, end); linspace gives N points along that edge\n        val = np.linspace(*v, N)\n        consts = np.full(N, const)\n\n        # Random times for each boundary point\n        t = np.random.uniform(t_min, t_max, N)\n\n        # For horizontal edges (axis=1): x varies, y is constant\n        # For vertical edges   (axis=0): y varies, x is constant\n        if axis == 0:\n            # Vertical edge: x is constant, val is y\n            pts.append(np.c_[consts, val, t])\n        else:\n            # Horizontal edge: y is constant, val is x\n            pts.append(np.c_[val, consts, t])\n\n    # Stack all four edge point sets into a single array of shape (4N,3)\n    return torch.tensor(np.vstack(pts), dtype=torch.float32).to(device)\n\n\n# ---------------------------------------------\n# Training loop (Adam optimizer)\n# ---------------------------------------------\nmodel = PINN().to(device)\nopt = torch.optim.Adam(model.parameters(), lr=1e-3)\n\nfor epoch in range(10000):\n    # Sample new collocation points for PDE, IC, and BC at each epoch.\n    xyt_f = sample_domain(2000)        # PDE collocation points\n    xyt_ic, u_ic = sample_ic(1000)     # IC points and labels\n    xyt_bc = sample_bc(500)            # BC points\n\n    # Compute three loss terms\n    lf = pde_loss(model, xyt_f)               # physics (PDE) loss\n    li = ic_loss(model, xyt_ic, u_ic)         # initial condition loss\n    lb = bc_loss(model, xyt_bc)               # boundary condition loss\n\n    # Total loss with weights: IC and BC are scaled up to enforce them strongly\n    loss = lf + 1000 * li + 100 * lb\n\n    # Standard PyTorch training step\n    opt.zero_grad()\n    loss.backward()\n    opt.step()\n\n    # Print progress every 500 epochs\n    if epoch % 500 == 0:\n        print(\n            f\"Epoch {epoch}: \"\n            f\"Total={loss.item():.4f} \"\n            f\"PDE={lf.item():.4f} \"\n            f\"IC={li.item():.4f} \"\n            f\"BC={lb.item():.4f}\"\n        )\n\n\n# ---------------------------------------------\n# Generate predictions on a regular (x,y) grid\n# and make an animation over time\n# ---------------------------------------------\n\n# 2D spatial grid for visualization: 101×101 points\nxg = np.linspace(x_min, x_max, 101)\nyg = np.linspace(y_min, y_max, 101)\nX, Y = np.meshgrid(xg, yg)\n\nframes = []  # list to store predicted u(x,y,t) for each time snapshot\n\n# Evaluate the model at 50 time instants between t=0 and t=10\nfor tval in np.linspace(0, 10, 50):\n    # Build (x,y,t) for all grid points at fixed time tval:\n    #   - X.ravel(), Y.ravel() → flatten to 1D arrays\n    #   - np.full_like(X.ravel(), tval) → same length, constant tval\n    xyt = np.stack(\n        [X.ravel(), Y.ravel(), np.full_like(X.ravel(), tval)],\n        axis=1\n    )  # shape (101*101, 3)\n\n    xyt_tensor = torch.tensor(xyt, dtype=torch.float32).to(device)\n\n    # Inference without gradients\n    with torch.no_grad():\n        # Predict u on the grid and reshape back to (101, 101)\n        u_pred = model(xyt_ten\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"### \"Finite Element Method\"\n# NOTE: This is actually an explicit finite-difference scheme for the\n#       2D advection–diffusion equation on a structured grid.\n\n# -----------------------------\n# Domain and discretization setup\n# -----------------------------\n\nL = 200          # Physical side length of the square domain in both x and y\nNx = 201         # Number of grid points in x-direction\nNy = 201         # Number of grid points in y-direction\nNt = 200         # Number of time steps\nT = 10.0         # Final simulation time\n\n# Spatial and temporal step sizes\ndx = L / (Nx - 1)    # Grid spacing in x (domain length / number of intervals)\ndy = L / (Ny - 1)    # Grid spacing in y\ndt = T / Nt          # Time step size\n\n# 1D coordinate arrays for x and y\nx = np.linspace(-100, 100, Nx)  # x ∈ [-100, 100]\ny = np.linspace(-100, 100, Ny)  # y ∈ [-100, 100]\n\n# 2D meshgrid: X[i,j], Y[i,j] give the physical coordinates of node (i,j)\nX, Y = np.meshgrid(x, y)\n\n# -----------------------------\n# Velocity field (radial)\n# -----------------------------\n\n# Radial distance from origin at each grid point\nR = np.sqrt(X**2 + Y**2)\n\n# a(x,y) = x / r , b(x,y) = y / r, but avoid division by zero at r=0\n# np.divide(..., where=R != 0) -> only divide where R != 0, otherwise use 0\na = np.divide(X, R, out=np.zeros_like(X), where=R != 0)\nb = np.divide(Y, R, out=np.zeros_like(Y), where=R != 0)\n\n# -----------------------------\n# Initial condition u(x,y,0)\n# -----------------------------\n\n# Allocate solution array at current time step, shape (Ny, Nx)\n# (row index corresponds to y, column index to x)\nu = np.zeros((Ny, Nx))\n\n# Initial \"blob\": u = 1 inside a circle of radius 12.5 centered at (0,0),\n#                 u = 0 elsewhere\nu[(X**2 + Y**2) < (12.5)**2] = 1.0\n\n# List to store solution snapshots for visualization\nframes = []\n\n# -----------------------------\n# Time-stepping loop\n# -----------------------------\nfor n in range(Nt):\n    # Copy current solution to u_new, which will store u^{n+1}\n    u_new = u.copy()\n\n    # Arrays for first and second derivatives\n    u_x = np.zeros_like(u)    # first derivative ∂u/∂x\n    u_y = np.zeros_like(u)    # first derivative ∂u/∂y\n    u_xx = np.zeros_like(u)   # second derivative ∂²u/∂x²\n    u_yy = np.zeros_like(u)   # second derivative ∂²u/∂y²\n\n    # -----------------------------\n    # Spatial derivatives (finite differences)\n    # -----------------------------\n\n    # Upwind scheme in x-direction:\n    #   u_x ≈ (u[i,j] - u[i,j-1]) / dx   for interior points j = 1..Nx-2\n    #   Left neighbor is used → \"upwind\" with respect to positive x-direction.\n    u_x[:, 1:-1] = (u[:, 1:-1] - u[:, :-2]) / dx\n\n    # Upwind scheme in y-direction:\n    #   u_y ≈ (u[i,j] - u[i-1,j]) / dy   for interior points i = 1..Ny-2\n    u_y[1:-1, :] = (u[1:-1, :] - u[:-2, :]) / dy\n\n    # Second derivative in x (central difference):\n    #   u_xx ≈ (u[i,j+1] - 2u[i,j] + u[i,j-1]) / dx²\n    u_xx[:, 1:-1] = (u[:, 2:] - 2 * u[:, 1:-1] + u[:, :-2]) / dx**2\n\n    # Second derivative in y (central difference):\n    #   u_yy ≈ (u[i+1,j] - 2u[i,j] + u[i-1,j]) / dy²\n    u_yy[1:-1, :] = (u[2:, :] - 2 * u[1:-1, :] + u[:-2, :]) / dy**2\n\n    # -----------------------------\n    # Explicit time update (Euler forward)\n    # -----------------------------\n    # For interior nodes (excluding boundaries), update using:\n    #\n    #   u^{n+1} = u^{n}\n    #             + dt * [ -a u_x - b u_y + u_xx + u_yy ]\n    #\n    # which corresponds to:\n    #   u_t + a u_x + b u_y = u_xx + u_yy\n    #\n    u_new[1:-1, 1:-1] += dt * (\n        -a[1:-1, 1:-1] * u_x[1:-1, 1:-1]\n        -b[1:-1, 1:-1] * u_y[1:-1, 1:-1]\n        + u_xx[1:-1, 1:-1]\n        + u_yy[1:-1, 1:-1]\n    )\n\n    # -----------------------------\n    # Neumann boundary conditions (zero normal derivative)\n    # -----------------------------\n    # Neumann BC ∂u/∂n = 0 is enforced by copying interior neighbor values:\n    #\n    #   left boundary   (x = x_min):  u[:, 0]  = u[:, 1]\n    #   right boundary  (x = x_max):  u[:, -1] = u[:, -2]\n    #   bottom boundary (y = y_min):  u[0, :]  = u[1, :]\n    #   top boundary    (y = y_max):  u[-1,:]  = u[-2,:]\n    #\n    u_new[:, 0] = u_new[:, 1]\n    u_new[:, -1] = u_new[:, -2]\n    u_new[0, :] = u_new[1, :]\n    u_new[-1, :] = u_new[-2, :]\n\n    # Update solution for next time step\n    u = u_new.copy()\n\n    # Store every 5th time step for animation (coarser temporal sampling)\n    if n % 5 == 0:\n        frames.append(u.copy())\n\n\n# -----------------------------\n# Visualization: contour animation\n# -----------------------------\nfig, ax = plt.subplots(figsize=(6, 5))\n\n# Initial contour plot at the first stored frame\ncontour = ax.contourf(X, Y, frames[0], levels=50, cmap='plasma')\nfig.colorbar(contour)\n\ndef update(frame_idx):\n    \"\"\"\n    Update function for the animation.\n\n    Args:\n        frame_idx: index into 'frames' list (0,1,2,...)\n\n    Plots u(x,y,t) at the corresponding time and updates the title.\n    \"\"\"\n    ax.clear()\n    # Each stored frame corresponds to 5 time steps → effective time = frame_idx * dt * 5\n    ax.set_title(f\"Time = {frame_idx * dt * 5:.2f} s\")\n    ax.contourf(X, Y, frames[frame_idx], levels=50, cmap='plasma')\n    return []\n\n# Build the animation: frames=len(frames) and 100 ms between frames\nani = animation.FuncAnimation(fig, update, frames=len(frames), interval=100)\n\n# Convert animation to JS/HTML for display in a Jupyter notebook\nHTML(ani.to_jshtml())\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# === Match PINN and FDM frames (aligning t values) ===\n\nframes_pinn = []  # list to store PINN snapshots u_PINN(x,y,t) for each time\n\n# t-values used by the FDM animation (same number of frames)\n# We want PINN predictions at exactly the same times for fair comparison.\nt_vals = np.linspace(0, 10, len(frames))  # frames = list of FDM snapshots\n\nfor tval in t_vals:\n    # Build a grid of (x, y, t) points for the current time tval:\n    #   - X.ravel(), Y.ravel() give flattened spatial coordinates\n    #   - np.full_like(X.ravel(), tval) gives a matching-length array with constant tval\n    xyt = np.stack(\n        [X.ravel(), Y.ravel(), np.full_like(X.ravel(), tval)],\n        axis=1\n    )  # shape: (Nx*Ny, 3)\n\n    # Convert to a PyTorch tensor and move to the chosen device (CPU/GPU)\n    xyt_tensor = torch.tensor(xyt, dtype=torch.float32).to(device)\n\n    # Predict u(x,y,tval) using the trained PINN without tracking gradients\n    with torch.no_grad():\n        # model output is (Nx*Ny, 1); reshape to (Ny, Nx) to match FDM grid layout\n        u_pred = model(xyt_tensor).cpu().numpy().reshape(X.shape)\n\n    # Store this time slice in the list of PINN frames\n    frames_pinn.append(u_pred)\n\n\n# === 1. Animated Side-by-Side Contour Plot ===\n\n# Create a figure with two subplots side-by-side:\n#   ax1: FDM solution\n#   ax2: PINN solution\nfig, (ax1, ax2) = plt.subplots(1, 2, figsize=(10, 4))\n\n# Initial contour plots for time t = t_vals[0]\nc1 = ax1.contourf(X, Y, frames[0], cmap='plasma', levels=50)\nc2 = ax2.contourf(X, Y, frames_pinn[0], cmap='plasma', levels=50)\n\n# Separate colorbars for each subplot\nfig.colorbar(c1, ax=ax1)\nfig.colorbar(c2, ax=ax2)\n\ndef update(frame_idx):\n    \"\"\"\n    Update function for the side-by-side FDM vs PINN animation.\n\n    Args:\n        frame_idx: index of the current frame (0..len(frames)-1)\n\n    Behavior:\n        - Clears both axes.\n        - Sets titles indicating the method and current time.\n        - Draws contour plots of FDM and PINN solutions at that time.\n    \"\"\"\n    # Clear previous contours\n    ax1.clear()\n    ax2.clear()\n\n    # Titles show which method and the corresponding time value\n    ax1.set_title(f\"FDM t={t_vals[frame_idx]:.2f}\")\n    ax2.set_title(f\"PINN t={t_vals[frame_idx]:.2f}\")\n\n    # Axis labels for both plots\n    ax1.set_xlabel(\"x\")\n    ax1.set_ylabel(\"y\")\n    ax2.set_xlabel(\"x\")\n    ax2.set_ylabel(\"y\")\n\n    # Draw updated filled contour plots for FDM (left) and PINN (right)\n    ax1.contourf(X, Y, frames[frame_idx], cmap='plasma', levels=50)\n    ax2.contourf(X, Y, frames_pinn[frame_idx], cmap='plasma', levels=50)\n    \n    return []  # required by FuncAnimation, even if we don't return artists\n\n# Create the animation over all stored frames\n# interval=100 → 100 ms between frames (≈10 fps)\nani = animation.FuncAnimation(fig, update, frames=len(frames), interval=100)\n\n# Save the animation as a GIF file using the Pillow writer\nani.save(\"comparison.gif\", writer=\"pillow\", fps=10)\n\n# Display the animation inline in a Jupyter notebook\nHTML(ani.to_jshtml())\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"snap_times = [0, 2.5, 5.0, 7.5, 10.0]\nsnap_indices = [np.argmin(np.abs(t_vals - t)) for t in snap_times]\n\nfor idx, t in zip(snap_indices, snap_times):\n    fig, axs = plt.subplots(1, 2, figsize=(10, 4))\n    axs[0].set_title(f\"FDM at t={t:.1f}\")\n    axs[1].set_title(f\"PINN at t={t:.1f}\")\n    ax1.set_xlabel(\"x\")\n    ax1.set_ylabel(\"y\")\n    ax2.set_xlabel(\"x\")\n    ax2.set_ylabel(\"y\")\n    axs[0].contourf(X, Y, frames[idx], cmap='plasma', levels=50)\n    axs[1].contourf(X, Y, frames_pinn[idx], cmap='plasma', levels=50)\n    plt.tight_layout()\n    plt.show()","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"y0_index = np.argmin(np.abs(y))  # index where y ≈ 0\n\nfor idx, t in zip(snap_indices, snap_times):\n    u_fdm_line = frames[idx][y0_index, :]\n    u_pinn_line = frames_pinn[idx][y0_index, :]\n    plt.figure(figsize=(6,4))\n    plt.plot(x, u_fdm_line, label='FDM', linewidth=2)\n    plt.plot(x, u_pinn_line, '--', label='PINN', linewidth=2)\n    plt.title(f\"Centerline at y=0, t={t:.1f}\")\n    plt.xlabel(\"x\"); plt.ylabel(\"u(x,0,t)\")\n    plt.legend(); plt.grid(True)\n    plt.show()","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}